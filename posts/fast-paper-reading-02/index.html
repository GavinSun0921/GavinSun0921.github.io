<!DOCTYPE html>
<html
  lang="en"
  dir="ltr"
  
><meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">


<title>[Skim-read] Image Super-Resolution via Iterative Refinement | Gavin&#39;s Blog</title>

<meta name="generator" content="Hugo Eureka 0.9.3" />
<link rel="stylesheet" href="https://gavinsun0921.github.io/css/eureka.min.9cec6350e37e534b0338fa9a085bf06855de3b0f2dcf857e792e5e97b07ea905d4d5513db554cbc26a9c3da622bae92d.css">
<script defer src="https://gavinsun0921.github.io/js/eureka.min.e8043b71b627e3cfd9b2a5de56adf007f5af83dee672ca0c186aa2e29a10d6f648632064d0c00b2fa4d1b11e0f196af3.js"></script>













<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link rel="preload"
  href="https://fonts.googleapis.com/css2?family=Lora:wght@400;600;700&amp;family=Noto&#43;Serif&#43;SC:wght@400;600;700&amp;display=swap"
  as="style" onload="this.onload=null;this.rel='stylesheet'">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.4.0/build/styles/base16/solarized-light.min.css"
   media="print"
  onload="this.media='all';this.onload=null" crossorigin>
<script defer src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.4.0/build/highlight.min.js"
   crossorigin></script>
  <script defer src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.4.0/build/languages/dart.min.js"
     crossorigin></script>
<link rel="stylesheet" href="https://gavinsun0921.github.io/css/highlightjs.min.2958991528e43eb6fc9b8c4f2b8e052f79c4010718e1d1e888a777620e9ee63021c2c57ec7417a3108019bb8c41943e6.css" media="print" onload="this.media='all';this.onload=null">


<script defer type="text/javascript" src="https://gavinsun0921.github.io/js/fontawesome.min.8c77c7521b1f95ec2031c2a79f5c6a698aa4a0dba5ba649dfbc7f73994cddf3f494be6aac7e5724f35cbf72cfde09703.js"></script>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css"
   integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ"  media="print"
  onload="this.media='all';this.onload=null" crossorigin>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js" 
  integrity="sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY"  crossorigin></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js"
   integrity="sha384-&#43;XBljXPPiv&#43;OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR"  crossorigin></script>
<script>
  document.addEventListener("DOMContentLoaded", function () {
    renderMathInElement(document.body, {
      delimiters: [
        { left: "$$", right: "$$", display: true },
        { left: "$", right: "$", display: false },
        { left: "\\(", right: "\\)", display: false },
        { left: "\\[", right: "\\]", display: true }
      ],
    });
  });
</script>




<link rel="icon" type="image/png" sizes="32x32" href="https://gavinsun0921.github.io/images/profile_hucaa8c691112995772162609a17edd22e_212855_32x32_fill_box_center_3.png">
<link rel="apple-touch-icon" sizes="180x180" href="https://gavinsun0921.github.io/images/profile_hucaa8c691112995772162609a17edd22e_212855_180x180_fill_box_center_3.png">

<meta name="description"
  content="Image super-resolution with conditional diffusion model.">
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
      "@type": "ListItem",
      "position": 1 ,
      "name":"Posts",
      "item":"https://gavinsun0921.github.io/posts/"},{
      "@type": "ListItem",
      "position": 2 ,
      "name":"[Skim-read] Image Super-Resolution via Iterative Refinement",
      "item":"https://gavinsun0921.github.io/posts/fast-paper-reading-02/"}]
}
</script>



<script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://gavinsun0921.github.io/posts/fast-paper-reading-02/"
    },
    "headline": "[Skim-read] Image Super-Resolution via Iterative Refinement | Gavin\u0027s Blog",
    "image": "https://gavinsun0921.github.io/images/fast-paper-reading/02.png",
    "datePublished": "2023-08-05T13:53:33+08:00",
    "dateModified": "2023-08-05T13:53:33+08:00",
    "wordCount":  1021 ,
    "publisher": {
        "@type": "Person",
        "name": "Gavin Sun",
        "logo": {
            "@type": "ImageObject",
            "url": "https://gavinsun0921.github.io/images/profile.png"
        }
        },
    "description": "Image super-resolution with conditional diffusion model."
}
</script><meta property="og:title" content="[Skim-read] Image Super-Resolution via Iterative Refinement | Gavin&#39;s Blog" />
<meta property="og:type" content="article" />


<meta property="og:image" content="https://gavinsun0921.github.io/images/profile.png">


<meta property="og:url" content="https://gavinsun0921.github.io/posts/fast-paper-reading-02/" />



<meta property="og:description" content="Image super-resolution with conditional diffusion model." />



<meta property="og:locale" content="en" />




<meta property="og:site_name" content="Gavin&#39;s Blog" />






<meta property="article:published_time" content="2023-08-05T13:53:33&#43;08:00" />


<meta property="article:modified_time" content="2023-08-05T13:53:33&#43;08:00" />



<meta property="article:section" content="posts" />


<meta property="article:tag" content="Diffusion" />

<meta property="article:tag" content="DPM" />

<meta property="article:tag" content="Computer Vision" />

<meta property="article:tag" content="Low-level Vision" />

<meta property="article:tag" content="Deep Learning" />









<meta property="og:see_also" content="https://gavinsun0921.github.io/posts/fast-paper-reading-03/" />





<meta property="og:see_also" content="https://gavinsun0921.github.io/posts/fast-paper-reading-01/" />






  <body class="flex min-h-screen flex-col">
    <header
      class="min-h-16 pl-scrollbar bg-secondary-bg fixed z-50 flex w-full items-center shadow-sm"
    >
      <div class="mx-auto w-full max-w-screen-xl"><script>
    let storageColorScheme = localStorage.getItem("lightDarkMode")
    if ((storageColorScheme == 'Auto' && window.matchMedia("(prefers-color-scheme: dark)").matches) || storageColorScheme == "Dark") {
        document.getElementsByTagName('html')[0].classList.add('dark')
    }
</script>
<nav class="flex items-center justify-between flex-wrap px-4 py-4 md:py-0">
    <a href="/" class="me-6 text-primary-text text-xl font-bold">Gavin&#39;s Blog</a>
    <button id="navbar-btn" class="md:hidden flex items-center px-3 py-2" aria-label="Open Navbar">
        <i class="fas fa-bars"></i>
    </button>

    <div id="target"
        class="hidden block md:flex md:grow md:justify-between md:items-center w-full md:w-auto text-primary-text z-20">
        <div class="md:flex md:h-16 text-sm md:grow pb-4 md:pb-0 border-b md:border-b-0">
            <a href="/posts/" class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2  selected-menu-item  me-4">Posts</a>
            <a href="/categories" class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2  border-transparent  me-4">Categories</a>
            <a href="/series" class="block mt-4 md:inline-block md:mt-0 md:h-(16-4px) md:leading-(16-4px) box-border md:border-t-2 md:border-b-2  border-transparent  me-4">Series</a>
        </div>

        <div class="flex">
            <div class="relative pt-4 md:pt-0">
                <div class="cursor-pointer hover:text-eureka" id="lightDarkMode">
                    <i class="fas fa-sun"></i>
                </div>
                <div class="fixed hidden inset-0 opacity-0 h-full w-full cursor-default z-30" id="is-open">
                </div>
                <div class="absolute flex flex-col start-0 md:start-auto end-auto md:end-0 hidden bg-secondary-bg w-48 rounded py-2 border border-tertiary-bg cursor-pointer z-40"
                    id='lightDarkOptions'>
                    <span class="px-4 py-1 hover:text-eureka" name="Light">Light</span>
                    <span class="px-4 py-1 hover:text-eureka" name="Dark">Dark</span>
                    <span class="px-4 py-1 hover:text-eureka" name="Auto">Auto</span>
                </div>
            </div>
        </div>
    </div>

    <div class="fixed hidden inset-0 opacity-0 h-full w-full cursor-default z-0" id="is-open-mobile">
    </div>

</nav>
<script>
    
    let element = document.getElementById('lightDarkMode')
    if (storageColorScheme == 'Auto') {
        element.firstElementChild.classList.remove('fa-sun')
        element.firstElementChild.setAttribute("data-icon", 'adjust')
        element.firstElementChild.classList.add('fa-adjust')
        document.addEventListener('DOMContentLoaded', () => {
            window.matchMedia("(prefers-color-scheme: dark)").addEventListener('change', switchDarkMode)
        })
    } else if (storageColorScheme == "Dark") {
        element.firstElementChild.classList.remove('fa-sun')
        element.firstElementChild.setAttribute("data-icon", 'moon')
        element.firstElementChild.classList.add('fa-moon')
    }

    document.addEventListener('DOMContentLoaded', () => {
        getcolorscheme();
        switchBurger();
    });
</script>
</div>
    </header>
    <main class="grow pt-16">
        <div class="pl-scrollbar">
          <div class="mx-auto w-full max-w-screen-xl lg:px-4 xl:px-8">
  
  
  <div class="grid grid-cols-2 gap-4 lg:grid-cols-8 lg:pt-12">
    <div
      class=" bg-secondary-bg col-span-2 rounded px-6 py-8 lg:col-span-6"
    >
      <article class="prose">
  <h1 class="mb-4">[Skim-read] Image Super-Resolution via Iterative Refinement</h1>

  <div
  class="text-tertiary-text not-prose mt-2 flex flex-row flex-wrap items-center"
>
  <div class="me-6 my-2">
    <i class="fas fa-calendar me-1"></i>
    <span
      >2023-08-05</span
    >
  </div>
  <div class="me-6 my-2">
    <i class="fas fa-clock me-1"></i>
    <span>5 min read</span>
  </div>

  
    <div class="me-6 my-2">
      <i class="fas fa-folder me-1"></i>
      
        <a href="https://gavinsun0921.github.io/categories/computer-vision/" class="hover:text-eureka"
          >Computer Vision</a
        >
      
        
          <span>, </span>
        <a href="https://gavinsun0921.github.io/categories/diffusion/" class="hover:text-eureka"
          >Diffusion</a
        >
      
    </div>
  

  
    <div class="me-6 my-2">
      <i class="fas fa-th-list me-1"></i>
      
        <a href="https://gavinsun0921.github.io/series/paper-skim-read/" class="hover:text-eureka"
          >Paper Skim-read</a
        >
      
    </div>
  
</div>


  
  
    <img src="https://gavinsun0921.github.io/images/fast-paper-reading/02.png" class="w-full" alt="Featured Image">
  

  <ul>
<li><strong><a href="https://ieeexplore.ieee.org/document/9887996"><strong>This paper</strong></a> is published in TPAMI 2023.</strong></li>
</ul>
<h2 id="overview">Overview</h2>
<h3 id="problem">Problem</h3>
<ul>
<li>In the field of image super-resolution, existing approaches often suffer from various limitations; e.g., autoregressive models are prohibitively expensive for high-resolution image generation, Normalizing Flows (NFs) and variational autoencoders (VAEs) often yield sub-optimal sample quality, and GANs require carefully designed regularization and optimization tricks to tame optimization instability and model collapse.</li>
</ul>
<h3 id="solution">Solution</h3>
<ul>
<li>Present <strong>SR3</strong>, an approach to image super-resolution via repeated refinement based on DDPM.</li>
</ul>
<h3 id="results">Results</h3>
<ul>
<li>The high-frequency information of the image can be well resored compared to other methods.</li>
<li>Despite mediocre performance in SSIM and PSNR metrics, visualization and consistency are good.</li>
</ul>
<h2 id="related-work">Related Work</h2>
<h3 id="diffusion-probabilistic-models">Diffusion Probabilistic Models</h3>
<p>I&rsquo;ve written a blog about diffusion probabilistic models (DPM). It has the derivation of the basic formulas of the DPM as well as a simple code implementation.</p>
<ul>
<li><a href="https://gavinsun0921.github.io/posts/paper-reading-01/">A Breif Exploration to Diffusion Probabilistic Models with Code Implementation</a>.</li>
</ul>
<h2 id="method">Method</h2>
<div align="center">
<img src="conditional.png" style="zoom:40%" alt=""/>
Fig. 1. The forward diffusion process $q$ (left to right) gradually adds <br>Gaussian noise to the target image. The reverse inference process <br>$p$ (right to left) iteratively denoises the target image conditioned <br>on a source image x. (Image source: <a href="https://ieeexplore.ieee.org/document/9887996">Saharia <i>et al.</i> 2023</a>)
</div>
<p>SR3 is a model obtained by improving on DDPM. Instead of randomly generating images, low resolution images are used as conditions to generate images. The main changes in SR3 are:</p>
<ol>
<li>The low resolution image is concatenated to the original input (x_t-1) after bicubic interpolation to get a 6-channel tensor as the new input to the DDPM.
<blockquote>
<p>We experimented with more sophisticated methods of conditioning, such as using FiLM (<a href="https://ojs.aaai.org/index.php/AAAI/article/view/11671">Perez <em>et al.</em> 2018</a>), but we found that the simple concatenation yielded similar generation quality.</p>
</blockquote>
</li>
<li>Instead of sampling $\bar{\alpha}_t$ directly using timestep $t$ to compute the correlation variable and loss, a random value is sampled from the distribution $\bar{\alpha} \sim p(\bar{\alpha}) = U(\bar{\alpha}_{t-1}, \bar{\alpha}_{t})$. (Section 2.4 in <a href="https://ieeexplore.ieee.org/document/9887996">Saharia <em>et al.</em> 2023</a>)</li>
<li>The model receives noise level $\bar{\alpha}_t$ directly instead of timestamp $t$. This allows flexibility in adjusting the noise level and the number of sampling steps during inferring.</li>
</ol>
<h2 id="experrimental-study">Experrimental Study</h2>
<h3 id="new-metric-consistency">New metric: Consistency</h3>
<blockquote>
<p>As a measure of the consistentcy of the superresolution outputs, we compute MSE between the downsampled outputs and the low resolution inputs.</p>
</blockquote>
<h3 id="new-metric-classification-accuracy">New metric: Classification Accuracy</h3>
<p>In the field of low-level vision, metrics often do not comprehensively represent the quality of images. Therefore the effectiveness of low-level models is often evaluated in terms of proxy tasks.</p>
<p>This paper mirror the evalution setup of <a href="https://openaccess.thecvf.com/content_ECCV_2018/html/Yulun_Zhang_Image_Super-Resolution_Using_ECCV_2018_paper.html">Zhang <em>et al.</em> (2018)</a> and apply 4$\times$ superresolution models to 56$\times$56 center crops from the validation set of ImageNet.</p>
<h3 id="quantitative-results">Quantitative Results</h3>
<p>Compared to PULSE (<a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Menon_PULSE_Self-Supervised_Photo_Upsampling_via_Latent_Space_Exploration_of_Generative_CVPR_2020_paper.html">Menon <em>et al.</em> 2020</a>), FSRGAN (<a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Chen_FSRNet_End-to-End_Learning_CVPR_2018_paper.html">Chen <em>et al.</em> 2018</a>), and Regressive models, the results in terms of PSNR and SSIM are relatively average. This is because traditional super-resolution models are typically trained based on PSNR, which SR3 is not. Therefore, it is normal for the metrics to be relatively low. However, the consistency metrics, on the other hand, perform very well.</p>
<div align="center">
Table 1. PSNR & SSIM on 16$\times$16 $\to$ 128$\times$128 face superresolution. <br>Consistency measures MSE ($\times10^{âˆ’5}$) between the lowresolution <br>inputs and the down-sampled super-resolution outputs. (Table <br>source: <a href="https://ieeexplore.ieee.org/document/9887996">Saharia <i>et al.</i> 2023</a> as a screenshot)
<img src="table1.png" style="zoom:30%" alt=""/>
</div>
<div align="center">
Table 2. Performance comparison between SR3 and Regression <br>baseline on natural image super-resolution using standard <br>metrics computed on the ImageNet validation set. (Table <br>source: <a href="https://ieeexplore.ieee.org/document/9887996">Saharia <i>et al.</i> 2023</a> as a screenshot)
<img src="table2.png" style="zoom:33%" alt=""/>
</div>
<h3 id="evaluation-of-proxy-task">Evaluation of Proxy Task</h3>
<ul>
<li>Object recognition baseline: ResNet-50 (<a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html">He <em>et al.</em> 2016</a>).</li>
</ul>
<div align="center">
Table 3. Comparison of classification accuracy scores for 4$\times$ natural <br>image super-resolution on the first 1K images from the ImageNet <br>Validation set. (Table source: <a href="https://ieeexplore.ieee.org/document/9887996">Saharia <i>et al.</i> 2023</a> as a screenshot)
<img src="table3.png" style="zoom:35%" alt=""/>
</div>
<h3 id="human-evaluation-2afc">Human Evaluation (2AFC)</h3>
<p>This paper use a 2-alternative forced-choice (2AFC) paradigm to measure how well humans can discriminate true images from those generated from a model.</p>
<div align="center">
<img src="human1.png" style="zoom:45%" alt=""/>
Fig. 2. Face super-resolution human fool rates (higher is better, <br>photo-realistic samples yield a fool rate of 50%). Outputs of 4 <br>models are compared against ground truth. (top) Subjects are <br>shown low-resolution inputs. (bottom) Inputs are not shown. <br>(Image source: <a href="https://ieeexplore.ieee.org/document/9887996">Saharia <i>et al.</i> 2023</a>)
</div>
<div align="center">
<img src="human2.png" style="zoom:45%" alt=""/>
Fig. 3. ImageNet super-resolution fool rates (higher is better, <br>photo-realistic samples yield a fool rate of 50%). SR3 and Regression <br>outputs are compared against ground truth. (top) Subjects are shown <br>low-resolution inputs. (bottom) Inputs are not shown. (Image source: <br><a href="https://ieeexplore.ieee.org/document/9887996">Saharia <i>et al.</i> 2023</a>)
</div>
<h3 id="visualization">Visualization</h3>
<div align="center">
<img src="vision1.png" style="zoom:45%" alt=""/>
Fig. 3. Comparison of different methods on the 16$\times$16 $\to$ 128$\times$128 face <br>super-resolution task. Reference image has not been included because <br>of privacy concerns. (Image source: <a href="https://ieeexplore.ieee.org/document/9887996">Saharia <i>et al.</i> 2023</a>)
</div>
<div align="center">
<img src="vision2.png" style="zoom:75%" alt=""/>
Fig. 4. Results of a SR3 model (64$\times$64 $\to$ 512$\times$512), trained on FFHQ, and applied to <br>images outside of the training set, along with enlarged patches to show finer details. <br>(Image source: <a href="https://ieeexplore.ieee.org/document/9887996">Saharia <i>et al.</i> 2023</a>)
</div>
<p>Fig. 4 shows that the image obtained by SR3 has more details (high-frequency information of the image) compared to the regression model.</p>
<h2 id="summary">Summary</h2>
<p>SR3 employs a completely novel approach to super-resolution, distinct from previous approaches based on GANs and CNNs. It primarily generates high-resolution images by denoising progressively from low resolution images conditioned on diffusion models. In the experimental section, the PSNR and SSIM metrics show relatively less impressive performance compared to other methods. However, it outperforms the Regression model in terms of FID and IS metrics, which would be more convincing if PULSE and FSRGAN also be evaluated. Personally, I find the consistency metric not very meaningful. Still, its remarkable performance in proxy task compared to the Regression model is worth attention (through there is still a lack of experimental comparisons with PULSE and FSRGAN). The approach of using diffusion models for image super-resolution is effective, and there is potential for further research in the future.</p>
<h2 id="reference">Reference</h2>
<p>[1] Chitwan Saharia et al. <a href="https://ieeexplore.ieee.org/document/9887996">&ldquo;Image Super-Resolution via Iterative Refinement.&rdquo;</a> TPAMI 2023.</p>
<p>[2] Ethan Perez et al. <a href="https://ojs.aaai.org/index.php/AAAI/article/view/11671">&ldquo;FiLM: Visual Reasoning with a General Conditioning Layer.&rdquo;</a> AAAI 2018.</p>
<p>[3] Yulun Zhang et al. <a href="https://openaccess.thecvf.com/content_ECCV_2018/html/Yulun_Zhang_Image_Super-Resolution_Using_ECCV_2018_paper.html">&ldquo;Image Super-Resolution Using Very Deep Residual Channel Attention Networks.&rdquo;</a> ECCV 2018.</p>
<p>[4] Sachit Menon et al. <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Menon_PULSE_Self-Supervised_Photo_Upsampling_via_Latent_Space_Exploration_of_Generative_CVPR_2020_paper.html">&ldquo;PULSE: Self-Supervised Photo Upsampling via Latent Space Exploration of Generative Models.&rdquo;</a> CVPR 2020.</p>
<p>[5] Yu Chen et al. <a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Chen_FSRNet_End-to-End_Learning_CVPR_2018_paper.html">&ldquo;FSRNet: End-to-End Learning Face Super-Resolution With Facial Priors.&rdquo;</a> CVPR 2018.</p>
<p>[6] Kaiming He et al. <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html">&ldquo;Deep residual learning for image recognition.&rdquo;</a> CVPR 2016.</p>

</article>


      
        <div class="my-4">
    
    <a href="https://gavinsun0921.github.io/tags/diffusion/" class="inline-block bg-tertiary-bg text-sm rounded px-3 py-1 my-1 me-2 hover:text-eureka">#Diffusion</a>
    
    <a href="https://gavinsun0921.github.io/tags/dpm/" class="inline-block bg-tertiary-bg text-sm rounded px-3 py-1 my-1 me-2 hover:text-eureka">#DPM</a>
    
    <a href="https://gavinsun0921.github.io/tags/computer-vision/" class="inline-block bg-tertiary-bg text-sm rounded px-3 py-1 my-1 me-2 hover:text-eureka">#Computer Vision</a>
    
    <a href="https://gavinsun0921.github.io/tags/low-level-vision/" class="inline-block bg-tertiary-bg text-sm rounded px-3 py-1 my-1 me-2 hover:text-eureka">#Low-level Vision</a>
    
    <a href="https://gavinsun0921.github.io/tags/deep-learning/" class="inline-block bg-tertiary-bg text-sm rounded px-3 py-1 my-1 me-2 hover:text-eureka">#Deep Learning</a>
    
</div>
      

      



      

      
  <div
    class="-mx-2 mt-4 flex flex-col border-t px-2 pt-4 md:flex-row md:justify-between"
  >
    <div>
      
        <span class="text-primary-text block font-bold"
          >Previous</span
        >
        <a href="https://gavinsun0921.github.io/posts/fast-paper-reading-03/" class="block">[Skim-read] Generative Modeling by Estimating Gradients of the Data Distribution</a>
      
    </div>
    <div class="mt-4 md:mt-0 md:text-right">
      
        <span class="text-primary-text block font-bold">Next</span>
        <a href="https://gavinsun0921.github.io/posts/fast-paper-reading-01/" class="block">[Skim-read] Deblurring via Stochastic Refinement</a>
      
    </div>
  </div>


      



  <script id="utterances" src="https://utteranc.es/client.js"
            issue-term=pathname
            repo=GavinSun0921/gavinsun0921.github.io
              theme=github-light
        crossorigin="anonymous"
        async>
</script>
<script>
    if (storageColorScheme == "Auto") {
      document.getElementById('utterances').setAttribute('theme', 'preferred-color-scheme')
    } else if (storageColorScheme == "Dark") {
      document.getElementById('utterances').setAttribute('theme', 'github-dark')
    }
</script>

    </div>
    
      <div class="col-span-2">
        
          
<div class="bg-secondary-bg prose max-w-none rounded p-6">
  <h3>Series of Posts</h3>
  
    
      <a href="https://gavinsun0921.github.io/posts/fast-paper-reading-03/" class="no-underline">[Skim-read] Generative Modeling by Estimating Gradients of the Data Distribution</a>
      <br />
    
      <a href="https://gavinsun0921.github.io/posts/fast-paper-reading-02/" class="no-underline">[Skim-read] Image Super-Resolution via Iterative Refinement</a>
      <br />
    
      <a href="https://gavinsun0921.github.io/posts/fast-paper-reading-01/" class="no-underline">[Skim-read] Deblurring via Stochastic Refinement</a>
      <br />
    
  
</div>

        
        
          <div
  class="
    bg-primary-bg
   prose sticky top-16 z-10 hidden px-6 py-4 lg:block"
>
  <h3>On This Page</h3>
</div>
<div
  class="sticky-toc  hidden px-6 pb-6 lg:block"
>
  <nav id="TableOfContents">
  <ul>
    <li><a href="#overview">Overview</a>
      <ul>
        <li><a href="#problem">Problem</a></li>
        <li><a href="#solution">Solution</a></li>
        <li><a href="#results">Results</a></li>
      </ul>
    </li>
    <li><a href="#related-work">Related Work</a>
      <ul>
        <li><a href="#diffusion-probabilistic-models">Diffusion Probabilistic Models</a></li>
      </ul>
    </li>
    <li><a href="#method">Method</a></li>
    <li><a href="#experrimental-study">Experrimental Study</a>
      <ul>
        <li><a href="#new-metric-consistency">New metric: Consistency</a></li>
        <li><a href="#new-metric-classification-accuracy">New metric: Classification Accuracy</a></li>
        <li><a href="#quantitative-results">Quantitative Results</a></li>
        <li><a href="#evaluation-of-proxy-task">Evaluation of Proxy Task</a></li>
        <li><a href="#human-evaluation-2afc">Human Evaluation (2AFC)</a></li>
        <li><a href="#visualization">Visualization</a></li>
      </ul>
    </li>
    <li><a href="#summary">Summary</a></li>
    <li><a href="#reference">Reference</a></li>
  </ul>
</nav>
</div>
<script>
  window.addEventListener("DOMContentLoaded", () => {
    enableStickyToc();
  });
</script>

        
      </div>
    

    
    
      <div
        class=" bg-secondary-bg prose col-span-2 rounded p-6 lg:col-span-6"
      >
        <h3>See Also</h3>
        
          <a href="https://gavinsun0921.github.io/posts/fast-paper-reading-01/" class="no-underline">[Skim-read] Deblurring via Stochastic Refinement</a>
          <br />
        
          <a href="https://gavinsun0921.github.io/posts/paper-research-01/" class="no-underline">A Breif Exploration to Diffusion Probabilistic Models with Code Implementation</a>
          <br />
        
      </div>
    
  </div>

  
    <script>
      document.addEventListener("DOMContentLoaded", () => {
        hljs.highlightAll();
      });
    </script>

          </div>
        </div>
      
    </main>
    <footer class="pl-scrollbar">
      <div class="mx-auto w-full max-w-screen-xl"><div class="text-center p-6 pin-b">
    <p class="text-sm text-tertiary-text">&copy; 2023 <a href="https://github.com/GavinSun0921">Gavin Sun</a>
 &middot;  Powered by the <a href="https://github.com/wangchucheng/hugo-eureka" class="hover:text-eureka">Eureka</a> theme for <a href="https://gohugo.io" class="hover:text-eureka">Hugo</a></p>
</div></div>
    </footer>
  </body>
</html>
